# ğŸ§  AI-Driven Multimodal ADHD Screening & Attention Enhancement Platform

---

## ğŸ” Project Overview

This project presents an **AI-driven, multimodal ADHD screening and attention enhancement platform** designed for **children aged 6â€“10**, with a strong focus on **Sri Lankan and Sinhala-speaking contexts**.

The system integrates **speech analysis**, **handwriting assessment**, **body posture and hyperactivity tracking**, and **eye-trackingâ€“based visual attention analysis** to provide an **objective, scalable, and non-invasive ADHD screening solution**.

> âš ï¸ **Important Note**  
> This system is intended for **SCREENING purposes only** and **does not provide a medical diagnosis**.  
> Results must be interpreted by qualified healthcare professionals.

---

## â— Problem Statement

Traditional ADHD diagnosis relies heavily on:
- Lengthy clinical interviews  
- Subjective behavioral observations  
- Expensive and inaccessible tools (e.g., EEG, lab-grade eye trackers)  

These approaches are often:
- Time-consuming  
- Costly  
- Difficult to scale for schools and community settings  
- Not child-friendly  

As a result, there is a **critical need for an accessible, engaging, and objective ADHD screening solution**, particularly in **resource-limited regions such as Sri Lanka**.

---

## ğŸ¯ Project Objectives

- Develop a **multimodal AI-based ADHD screening framework**
- Enable **early identification** using non-invasive behavioral data
- Support **Sinhala-speaking children** through culturally adapted tasks
- Integrate **screening and attention enhancement** within a single platform
- Ensure **privacy, ethical compliance, and child-friendly interaction**

---

## ğŸ“ Project Description

This project proposes an AI-driven, multimodal screening platform to support the **early identification of ADHD-related behavioral patterns** in children aged **6â€“10 years**.  

Multiple non-invasive data sourcesâ€”including **speech**, **handwriting**, **posture**, and **eye-tracking**â€”are combined to generate an objective ADHD risk assessment and to recommend appropriate attention improvement activities.

---

## ğŸ—ï¸ System Architecture

The platform follows a **modular, service-oriented architecture**, where each behavioral analysis component operates independently while contributing to a **unified ADHD risk assessment**.

### ğŸ”„ High-Level Workflow
1. Children interact with **web-based tasks and games**
2. Multimodal data is captured (audio, video, gaze, handwriting)
3. Features are extracted and preprocessed
4. Machine learning models analyze behavioral patterns
5. Results are fused into an **ADHD risk score**
6. **Attention-improvement games** are recommended

### ğŸ“Œ System Architecture Diagram

<p align="center">
  <img src="Architecture/systemArchitecture.jpeg" alt="System Architecture Diagram" width="800"/>
</p>

---

## ğŸ“ Architecture Folder Contents & Evidence

The `Architecture/` folder contains **system design documentation and real-world evidence** related to this project.

### ğŸ“ Included Materials
- System architecture diagram
- School-based data collection photographs
- Lady Ridgeway Hospital data collection photographs
- Ethical clearance documentation

These materials are included **strictly for academic verification purposes**.

---

## ğŸ§ª Data Collection & Ethical Approval

### ğŸ“ Data Collection Locations
- Selected primary schools  
- **Lady Ridgeway Hospital for Children, Sri Lanka**

### ğŸ¥ Ethical Clearance
- Ethical approval was formally obtained from **Lady Ridgeway Hospital**
- Parental consent was obtained prior to data collection
- All activities adhered to:
  - Child safety guidelines  
  - Research ethics standards  
  - Data privacy and confidentiality requirements  

### ğŸ“¸ Ethical Clearance Evidence

<p align="center">
  <img src="Architecture/Picture8.jpeg" alt="Ethical Clearance Evidence" width="600"/>
</p>

---

## ğŸ§© Core System Components

### 1ï¸âƒ£ Speech-Based ADHD Screening
- Analysis of **Sinhala speech** during reading tasks  
- Extraction of **acoustic features** (MFCCs, pitch, jitter, shimmer)  
- Extraction of **linguistic features**  
- Classification using ML models (Random Forest, XGBoost, etc.)  
- Output of **probability-based ADHD indicators**

---

### 2ï¸âƒ£ Handwriting-Based ADHD Analysis
- Capture of handwriting dynamics (stroke patterns, pressure, timing)
- Identification of motor control and attention irregularities
- Support for early indicators of ADHD-related fine motor challenges

---

### 3ï¸âƒ£ Vision-Based Posture & Hyperactivity Detection
- Webcam-based posture and motion tracking
- Detection of excessive movement, restlessness, and impulsivity
- Extraction of motion-based behavioral biomarkers

---

### 4ï¸âƒ£ Eye-Tracking & Visual Attention Assessment
- Browser-based eye tracking using standard webcams
- Gamified assessment tasks:
  - Prosaccade
  - Antisaccade
  - Memory-guided saccade
- Extraction of gaze features (fixation duration, saccade latency, gaze entropy)
- Classification of attention patterns using machine learning

---

## ğŸ§  Machine Learning Pipeline

### ğŸ”¹ Processing Steps
- Data preprocessing and feature extraction
- Trainâ€“test split with cross-validation

### ğŸ”¹ Models Utilized
- Logistic Regression  
- Support Vector Machine (SVM)  
- Random Forest and Extra-Trees  
- CNN + LSTM (experimental)

### ğŸ”¹ Evaluation Metrics
- Accuracy  
- AUCâ€“ROC  
- Sensitivity and Specificity  

---

## ğŸ› ï¸ Technology Stack

### ğŸ¨ Frontend
- React.js  
- Tailwind CSS  
- HTML5 Canvas / WebGL  

### âš™ï¸ Backend
- FastAPI (Python)  
- RESTful API architecture  

### ğŸ¤– AI / Machine Learning
- Python  
- Scikit-learn  
- TensorFlow / PyTorch (experimental)

### ğŸ”Š Audio & Signal Processing
- Librosa  
- FFmpeg  
- PyDub  
- Praat-Parselmouth  

### ğŸ§  Natural Language Processing
- NLTK  
- spaCy  

### ğŸ‘ï¸ Computer Vision & Eye Tracking
- OpenCV  
- MediaPipe  
- WebGazer.js  

### ğŸ“Š Data Handling
- NumPy  
- Pandas  
- SciPy  

### ğŸ”„ Version Control
- Git  
- GitHub  

---

## ğŸ® Demo Games & Data Collection Tools

To support multimodal data collection and system validation, the following **web-based demo tools** were developed:

- ğŸ‘ï¸ Eye-Tracking Simulation  
  https://eye-tracking-simulation.vercel.app  

- ğŸ§ Pose & Hyperactivity Detection Games  
  https://adhd-poses-detection-games.vercel.app  

- ğŸ™ï¸ Speech-Based ADHD Data Collection  
  https://gb8222.github.io/speechBase  

- âœï¸ Handwriting Data Collection Tool  
  https://handwriting-data-collection.vercel.app  

---

## ğŸ“ Component Demonstration & Individual Contributions

Each team member independently developed and tested their assigned system component.

- Short demonstration and progress videos were recorded
- Videos illustrate component functionality, data flow, and feature extraction
- Materials are shared via Google Drive for evaluator access

ğŸ”— **Drive Link:**  
https://drive.google.com/drive/folders/1qcCdg-zrMsUxbjDFOUXC_EKRq9lXjNYP?usp=sharing

---

## ğŸ” Privacy, Ethics & Security

- No raw video or facial images are stored
- Only derived behavioral features are retained
- Participant identities are **pseudonymized**
- Secure data handling and encrypted storage
- Explicit parental consent is mandatory
- System design follows ethical guidelines for child data protection

---

## âš ï¸ Disclaimer

This system is developed **for academic research and screening purposes only**.  
It **does not replace professional medical diagnosis** and should be used solely as a supportive screening tool.

---


## ğŸ—‚ï¸ Project Structure Overview

The repository is organized in a **modular and collaborative structure** to support parallel development, clear version control, and academic evaluation.

```text
AI-Driven-Multimodal-ADHD-Screening/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ Architecture/
â”‚   â”œâ”€â”€ systemArchitecture.jpeg
â”‚   â”œâ”€â”€ ethical_clearance_lrh.jpeg
â”‚   â”œâ”€â”€ school_data_collection_photos/
â”‚   â””â”€â”€ hospital_data_collection_photos/
â”‚
â”œâ”€â”€ Proposals/
â”‚   â”œâ”€â”€ Speech_ADHD_Proposal.pdf
â”‚   â”œâ”€â”€ Handwriting_ADHD_Proposal.pdf
â”‚   â”œâ”€â”€ Posture_Hyperactivity_Proposal.pdf
â”‚   â””â”€â”€ EyeTracking_Attention_Proposal.pdf
â”‚
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ML_Models/
â”‚   â”œâ”€â”€ speech_model/
â”‚   â”œâ”€â”€ handwriting_model/
â”‚   â”œâ”€â”€ posture_model/
â”‚   â””â”€â”€ eye_tracking_model/
â”‚
â”œâ”€â”€ Demo_Games/
â”‚   â”œâ”€â”€ eye_tracking_demo/
â”‚   â”œâ”€â”€ posture_game/
â”‚   â”œâ”€â”€ speech_demo/
â”‚   â””â”€â”€ handwriting_demo/
â”‚
â”œâ”€â”€ Individual_Progress/
â”‚   â”œâ”€â”€ Member_1/
â”‚   â”œâ”€â”€ Member_2/
â”‚   â”œâ”€â”€ Member_3/
â”‚   â””â”€â”€ Member_4/
â”‚
â””â”€â”€ .gitignore
